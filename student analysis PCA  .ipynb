{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import anonomysed data\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import nbimporter \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from kneed import KneeLocator\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "path = r\"\"\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "df_list = []\n",
    "number = 0\n",
    "\n",
    "\n",
    "for path in dir_list:\n",
    "    df = pd.read_csv(r\"\".format(new_path = path))\n",
    "    df_list.append(df)\n",
    "    print(path, \"=\", number)\n",
    "    number+=1\n",
    "\n",
    "# numbers and names for analysis\n",
    "\n",
    "names = [\"term1\",\"term2\",\"term3\",\"gender1\",\"gender2\",\"class1\",\"class2\",\"class3\",\n",
    "                                           \"class4\",\"class5\",\"whole_cohort\"]\n",
    "\n",
    "numbers = [10,11,12,4,6,2,3,5,7,17,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cohort totals\n",
    "\n",
    "print(\"females = \",len(df_list[4]))\n",
    "print(\"males = \",len(df_list[6]))\n",
    "print(\"born in term 1 = \",len(df_list[10]))\n",
    "print(\"born in term 2 = \",len(df_list[11]))\n",
    "print(\"born in term 3 = \",len(df_list[12]))\n",
    "print(\"class 1 = \",len(df_list[2]))\n",
    "print(\"class 2 = \",len(df_list[3]))\n",
    "print(\"class 3 = \",len(df_list[5]))\n",
    "print(\"class 4 = \",len(df_list[7]))\n",
    "print(\"class 5 = \",len(df_list[17]))\n",
    "\n",
    "\n",
    "print(len(df_list[8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing modules\n",
    "\n",
    "\n",
    "from TapestryCleanAndModelPCAVariance3 import smashTogether\n",
    "from TapestryCleanAndModelPCAVariance3 import run_analysis\n",
    "from TapestryCleanAndModelPCAVariance3 import KMedoidsClass\n",
    "from TapestryCleanAndModelPCAVariance3 import findK\n",
    "from TapestryCleanAndModelPCAVariance3 import explained_variance\n",
    "\n",
    "\n",
    "# preparing frames\n",
    "\n",
    "#termsBorn = smashTogether(df_list, 10,11,12)\n",
    "\n",
    "#gender = smashTogether(df_list, 4,6)\n",
    "\n",
    "totalCohort = smashTogether(df_list, 2, 3, 5, 7, 17)\n",
    "\n",
    "\n",
    "# removing those not assigned a class \n",
    "# remember to use this have to change df_list above to old_df_list\n",
    "\n",
    "\n",
    "for df in df_list:\n",
    "    try:\n",
    "        df.drop('ID', axis=1, inplace=True)\n",
    "    except:\n",
    "        continue    \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# creating bar chart of each learning feature using total cohort \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for (number, analysis_name) in zip(numbers, names):\n",
    "    df = df_list[number]\n",
    "    cols = df.columns\n",
    "    sum_stats = df[cols].sum(axis=0).to_list()\n",
    "    sumDict = {'learning area': [\"CL\", \"PSED\", \n",
    "                             \"PD\", \"L\", \"M\", \"UW\", \n",
    "                              \"EAD\"],\n",
    "        'total observations':sum_stats}\n",
    "    bar_df = pd.DataFrame(sumDict)\n",
    "    sns.barplot(data=bar_df, x=\"learning area\", y=\"total observations\")\n",
    "    title = '{name} total observations for each learning area'.format(name = analysis_name)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('learning area')\n",
    "    plt.ylabel('total observations')\n",
    "    plt.savefig(\"D:\\Masters\\Research project\\Total observation graphs\\{name}.jpg\".format(name = analysis_name))\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating total tables\n",
    "\n",
    "for (number, analysis_name) in zip(numbers, names):\n",
    "    df = df_list[number]\n",
    "    cols = df.columns\n",
    "    sum_stats = df[cols].sum(axis=0).to_list()\n",
    "    sum_stats.append(sum(sum_stats))\n",
    "    sumDict = {'learning area': [\"CL\", \"PSED\", \n",
    "                             \"PD\", \"L\", \"M\", \"UW\", \n",
    "                              \"EAD\", \"Total\"],\n",
    "        'total observations':sum_stats}\n",
    "    bar_df = pd.DataFrame(sumDict)\n",
    "    print(analysis_name)\n",
    "    print(bar_df)\n",
    "    print()\n",
    "    bar_df.to_csv(r''.format(name = analysis_name), index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating cohort sizes\n",
    "\n",
    "print(\"size of whole cohort is \", len(df_list[8]))\n",
    "print(\"total number of observations is \", df_list[8].size)\n",
    "print(\"number of pupils in gender sample is \", 74+86)\n",
    "print(\"number of pupils in class sample is\",len(df_list[2])+len(df_list[3])+len(df_list[5])+len(df_list[7])+len(df_list[17]))\n",
    "print(\"number of pupils with birth given is \", len(df_list[10])+len(df_list[11])+ len(df_list[12]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create boxplots of observation counts for each subsample\n",
    "\n",
    "learningAreas = [\"CL\", \"PSED\", \n",
    "                             \"PD\", \"L\", \"M\", \"UW\", \n",
    "                              \"EAD\"]\n",
    "def boxPlots(df_list, numbers, names):\n",
    "    for (number, analysis_name) in zip(numbers, names):\n",
    "        df = df_list[number].iloc[:,0:7]\n",
    "        df.columns = [\"CL\", \"PSED\", \n",
    "                             \"PD\", \"L\", \"M\", \"UW\", \n",
    "                              \"EAD\"]\n",
    "        sns.boxplot(data=df)\n",
    "        title = '{name} observations for each learning area'.format(name = analysis_name)\n",
    "        plt.title(title)\n",
    "        plt.xlabel('learning area')\n",
    "        plt.ylabel('total observations')\n",
    "        plt.savefig(\"D:\\Masters\\Research project\\Total observation graphs\\{name}.jpg\".format(name = analysis_name))\n",
    "        plt.show()\n",
    "        \n",
    "boxPlots(df_list, numbers, names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describing each learning area for whole cohort \n",
    "\n",
    "learningAreaDesribe = df_list[8].describe(include='all')\n",
    "learningAreaDesribe.to_csv(r'')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create boxplots of variation in each learning area\n",
    "\n",
    "\n",
    "learningAreasDfs = []\n",
    "\n",
    "for learning_area in learningAreas:\n",
    "    df = pd.DataFrame()\n",
    "    learningAreasDfs.append(df)\n",
    "    \n",
    "newDfList = []\n",
    "\n",
    "for number in numbers:\n",
    "    newDfList.append(df_list[number])\n",
    "    \n",
    "count = 1\n",
    "for learningAreasDf in learningAreasDfs:\n",
    "    for (df, name) in zip(newDfList, names):\n",
    "        learningAreasDf[name] = df[str(count)]\n",
    "    count = count+1\n",
    "\n",
    "   \n",
    "        \n",
    "        \n",
    "for (name, number) in zip(learningAreas, range(0,7)): \n",
    "    ax= sns.boxplot(data=learningAreasDfs[number])\n",
    "    ax.set_xticklabels(ax.get_xticklabels(),rotation=30)\n",
    "    ax.set(title= name)\n",
    "    ax.set(xlabel=\"Subsample\", ylabel=\"Number of observations per individual\")\n",
    "    plt.savefig(\"\".format(name = name))\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(learningAreasDfs[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running kmeans analysis\n",
    "\n",
    "def kmeans_analysis(df_list,numbers, names):\n",
    "    silhouette_scores = []\n",
    "    ksMeans = []\n",
    "    for (number, name) in zip(numbers, names):\n",
    "        score, k = run_analysis(df_list[number], name)\n",
    "        silhouette_scores.append(score)\n",
    "        ksMeans.append(k)\n",
    "    return silhouette_scores, ksMeans\n",
    "    \n",
    "kmeansSilhouetteScores, ksMeans = kmeans_analysis(df_list,numbers,names)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k medoid analysis \n",
    "\n",
    "\n",
    "kmedoidSilhouetteScores = []\n",
    "ksMedoids = []\n",
    "for (number,name) in zip(numbers, names):\n",
    "    score, kProper = findK(df_list[number], name)\n",
    "    kmedoidSilhouetteScores.append(score)\n",
    "    ksMedoids.append(kProper)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding variance \n",
    "\n",
    "mxDf = pd.DataFrame()\n",
    "mnDf = pd.DataFrame()\n",
    "\n",
    "for number, name in zip(numbers, names):\n",
    "    df = explained_variance(df_list[number], name)\n",
    "    mx = df[df[\"Feature Contribution to Variance\"] == df[\"Feature Contribution to Variance\"].max()]\n",
    "    mn = df[df[\"Feature Contribution to Variance\"] == df[\"Feature Contribution to Variance\"].min()]\n",
    "    mxDf = mxDf.append(mx)\n",
    "    mnDf = mnDf.append(mn)\n",
    "mxDf.insert(0,'Sample', names)\n",
    "mnDf.insert(0,'Sample', names)\n",
    "mxDf = mxDf.drop([\"PC-1\",\"PC-2\"], axis=1)\n",
    "mnDf = mnDf.drop([\"PC-1\",\"PC-2\"], axis=1)\n",
    "mxDf.to_csv(r'', index=False)\n",
    "mnDf.to_csv(r'', index=False)\n",
    "print(\"max variance contributors\")\n",
    "print(mxDf)\n",
    "print()\n",
    "print(\"min variance contributors\")\n",
    "print(mnDf)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making tables \n",
    "\n",
    "\n",
    "dict = {'sample name':[\"term1\",\"term2\",\"term3\",\"gender1\",\"gender2\",\"class1\",\"class2\",\"class3\",\n",
    "                                           \"class4\",\"class5\",\"whole_cohort\"],\n",
    "        'kmeansSC':kmeansSilhouetteScores,\n",
    "        'kmedoidSC':kmedoidSilhouetteScores,\n",
    "        'kmeans k': ksMeans,\n",
    "        'kMedoids k': ksMedoids}\n",
    " \n",
    "scScoresAndKs = pd.DataFrame(dict)\n",
    "print(scScoresAndKs)\n",
    "scScoresAndKs.to_csv(r'', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
